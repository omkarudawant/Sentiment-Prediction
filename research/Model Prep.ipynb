{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Prediction\n",
    "\n",
    "\n",
    "### Building the model\n",
    "\n",
    "\n",
    "- We now have the preprocessed data, we'll first convert the **reviews** to **TfIdf** vectors to use them as features, as in order to build the model we can't work with plain text.\n",
    "\n",
    "\n",
    "- **TfIdf** are word frequency scores that try to highlight words that are more interesting, e.g. Frequent in a document but not across documents. The higher the TfIdf score, the rarer the term is.\n",
    "\n",
    "\n",
    "- We'll start with some basic models like Naive Bayes and Logistice Regression, and then move onto more complex ones like RandomForests, SVM, Decision trees and Extreme Gradient boosting.\n",
    "\n",
    "\n",
    "- To measure the performance of model, we'll mainly focus on F1 scores, but we'll also see how their other metrics like accuracy, recall, and precision score (although we're already looking at F1 score but sometimes it is not a reliable measure as it's just a harmonic mean of precision and recall and if there's large variation between them, F1 score might give us false picture of the model)\n",
    "\n",
    "\n",
    "- We'll need do one more step as we forgot to convert text based labels, **Positive/Negative** to 1 or 0, so we'll do that before splitting the dataset.\n",
    "\n",
    "\n",
    "- Also, as we have 50,000 datapoints we can use almost 80 to 85% of the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:13:06.627198Z",
     "start_time": "2020-09-30T17:13:06.601203Z"
    }
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:12:48.227628Z",
     "start_time": "2020-09-30T17:12:47.453288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewer have mention that af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production    the filming t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>think this be a wonderful way to spend time o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>basically there s a family where a little boy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>Petter Matteis Love in the Time of Money be a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                     cleaned_review\n",
       "0  positive  one of the other reviewer have mention that af...\n",
       "1  positive  a wonderful little production    the filming t...\n",
       "2  positive   think this be a wonderful way to spend time o...\n",
       "3  negative  basically there s a family where a little boy ...\n",
       "4  positive  Petter Matteis Love in the Time of Money be a ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/final_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:12:48.274646Z",
     "start_time": "2020-09-30T17:12:48.231628Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['cleaned_review']\n",
    "y = df['sentiment'].replace({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is ready to splitted into training and testing splits we'll first convert the reviews to Tf-Idf vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:12:48.290618Z",
     "start_time": "2020-09-30T17:12:48.277622Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:13:00.188452Z",
     "start_time": "2020-09-30T17:12:48.296622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.16 s, sys: 188 ms, total: 8.35 s\n",
      "Wall time: 8.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:13:00.268494Z",
     "start_time": "2020-09-30T17:13:00.192450Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:13:00.284451Z",
     "start_time": "2020-09-30T17:13:00.271471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 150143) (7500, 150143) (42500,) (7500,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll load the model objects in a list in order to test all of the models at once.\n",
    "\n",
    "\n",
    "- We'll also write a function to display all the metrics we're going to use to evaluate performance of the models.\n",
    "\n",
    "\n",
    "- Last but not the least, we'll also look at the time required to train the models, as it's also an important metric while deciding between 2 models if they are giving same accuracy/f1/any  scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:15:12.804448Z",
     "start_time": "2020-09-30T17:15:12.792446Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(n_jobs=-1),\n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    LinearSVC(),\n",
    "    XGBClassifier(n_jobs=-1),\n",
    "    DecisionTreeClassifier()\n",
    "]\n",
    "\n",
    "\n",
    "def display_metrics(true, pred):\n",
    "\n",
    "    f1 = round(f1_score(y_true=true, y_pred=pred) * 100)\n",
    "    precision = round(precision_score(y_true=true, y_pred=pred) * 100)\n",
    "    recall = round(recall_score(y_true=true, y_pred=pred) * 100)\n",
    "\n",
    "    print(f'F1: {f1}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:21:18.327145Z",
     "start_time": "2020-09-30T17:15:16.911363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> MultinomialNB\n",
      "Acc: 86\n",
      "F1: 86\n",
      "Precision: 87\n",
      "Recall: 84\n",
      "Training time: 0 seconds\n",
      "----------\n",
      "Training -> LogisticRegression\n",
      "Acc: 89\n",
      "F1: 89\n",
      "Precision: 88\n",
      "Recall: 90\n",
      "Training time: 6 seconds\n",
      "----------\n",
      "Training -> RandomForestClassifier\n",
      "Acc: 83\n",
      "F1: 83\n",
      "Precision: 83\n",
      "Recall: 83\n",
      "Training time: 41 seconds\n",
      "----------\n",
      "Training -> LinearSVC\n",
      "Acc: 89\n",
      "F1: 89\n",
      "Precision: 89\n",
      "Recall: 90\n",
      "Training time: 1 seconds\n",
      "----------\n",
      "Training -> XGBClassifier\n",
      "Acc: 85\n",
      "F1: 85\n",
      "Precision: 83\n",
      "Recall: 86\n",
      "Training time: 155 seconds\n",
      "----------\n",
      "Training -> DecisionTreeClassifier\n",
      "Acc: 71\n",
      "F1: 71\n",
      "Precision: 70\n",
      "Recall: 71\n",
      "Training time: 103 seconds\n",
      "----------\n",
      "CPU times: user 9min 39s, sys: 1.07 s, total: 9min 40s\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained_models = dict()\n",
    "\n",
    "for model in models:\n",
    "    print(f'Training -> {model.__class__.__name__}')\n",
    "    s = time.time()\n",
    "    trained_models[model.__class__.__name__] = model.fit(X_train, y_train)\n",
    "    e = time.time()\n",
    "    preds = trained_models[model.__class__.__name__].predict(X_test)\n",
    "    acc = round(accuracy_score(y_true=y_test, y_pred=preds) * 100)\n",
    "    print(f'Acc: {acc}')\n",
    "    display_metrics(true=y_test, pred=preds)\n",
    "    print(f'Training time: {round(e - s)} seconds')\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see above, Logistic regression and LinearSVM (SVM without a kernel, because our dataset is huge with more than 150k features so the time complexity O(datapoints x features^2) is not feasible) are giving best and similar metric scores.\n",
    "\n",
    "\n",
    "- Although these two models are same in terms of their metrics scores, but SVM is almost 6 times faster in terms of training time.\n",
    "\n",
    "\n",
    "- Also, SVM's precision is a little better by just 1%, that means out of the 90% correctly predicted positive labels(recall), 89% of them are actually positive(precision).\n",
    "\n",
    "\n",
    "- Although we can tune, LinearSVM for better value of the regularization parameter C, but we already have a good enough model for this task, so we won't do it.\n",
    "\n",
    "\n",
    "- Now, we'll store the model and the Tf-Idf vectorizer object by using joblib to use them in a webapp for setiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:54:05.815245Z",
     "start_time": "2020-09-30T17:54:05.800255Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:55:14.440480Z",
     "start_time": "2020-09-30T17:55:14.425481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear_svm.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(value=trained_models['LinearSVC'], filename='../app/models/linear_svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T17:55:27.631257Z",
     "start_time": "2020-09-30T17:55:26.265240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(value=tfidf, filename='../app/models/tfidf_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling part is also done, we'll move onto building the webapp using flask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
